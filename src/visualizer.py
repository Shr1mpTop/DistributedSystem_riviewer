"""
å¯è§†åŒ–åˆ†ææ¨¡å— - åˆ†æé¢˜å‹åˆ†å¸ƒå’ŒçŸ¥è¯†ç‚¹ç»Ÿè®¡
ä½œè€…: åˆ†å¸ƒå¼ç³»ç»Ÿè€ƒè¯•æŒ‡å—é¡¹ç›®ç»„
åŠŸèƒ½: ç”Ÿæˆå„ç§ç»Ÿè®¡å›¾è¡¨ï¼Œåˆ†æè€ƒè¯•è¶‹åŠ¿å’Œé‡ç‚¹
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import logging
from pathlib import Path
from typing import Dict, List, Any
import re
from collections import Counter

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class ExamVisualizer:
    def __init__(self):
        """åˆå§‹åŒ–å¯è§†åŒ–åˆ†æå™¨"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # è®¾ç½®é¢œè‰²ä¸»é¢˜
        self.colors = {
            'primary': '#2E86AB',
            'secondary': '#A23B72',
            'accent': '#F18F01',
            'success': '#C73E1D',
            'warning': '#FFC300',
            'info': '#4CAF50'
        }
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        self.output_dir = Path('output/visualizations')
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def load_data(self, csv_path: str = "output/questions_full.csv") -> pd.DataFrame:
        """åŠ è½½å¤„ç†åçš„é¢˜ç›®æ•°æ®"""
        try:
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            self.logger.info(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æ•°æ®")
            return df
        except FileNotFoundError:
            self.logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            return pd.DataFrame()
        except Exception as e:
            self.logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def analyze_question_types(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æé¢˜å‹åˆ†å¸ƒ"""
        type_counts = df['type'].value_counts()
        type_percentages = df['type'].value_counts(normalize=True) * 100
        
        analysis = {
            'counts': type_counts.to_dict(),
            'percentages': type_percentages.to_dict(),
            'total_types': len(type_counts),
            'most_common': type_counts.index[0] if not type_counts.empty else None,
            'least_common': type_counts.index[-1] if not type_counts.empty else None
        }
        
        return analysis
    
    def analyze_knowledge_points(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æçŸ¥è¯†ç‚¹åˆ†å¸ƒ"""
        # æå–æ‰€æœ‰çŸ¥è¯†ç‚¹
        all_knowledge_points = []
        for kp_str in df['knowledge_points'].dropna():
            if kp_str != 'æœªè¯†åˆ«':
                points = [kp.strip() for kp in kp_str.split(';')]
                all_knowledge_points.extend(points)
        
        # ç»Ÿè®¡çŸ¥è¯†ç‚¹é¢‘ç‡
        kp_counter = Counter(all_knowledge_points)
        
        analysis = {
            'total_unique_points': len(kp_counter),
            'top_10_points': dict(kp_counter.most_common(10)),
            'total_mentions': sum(kp_counter.values()),
            'coverage_rate': len([kp for kp in df['knowledge_points'] if kp != 'æœªè¯†åˆ«']) / len(df)
        }
        
        return analysis
    
    def plot_question_type_distribution(self, df: pd.DataFrame) -> str:
        """ç»˜åˆ¶é¢˜å‹åˆ†å¸ƒå›¾"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # é¢˜å‹è®¡æ•°æŸ±çŠ¶å›¾
        type_counts = df['type'].value_counts()
        bars1 = ax1.bar(range(len(type_counts)), type_counts.values, 
                       color=[self.colors['primary'], self.colors['secondary'], 
                             self.colors['accent'], self.colors['success']][:len(type_counts)])
        ax1.set_title('é¢˜å‹æ•°é‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax1.set_xlabel('é¢˜å‹')
        ax1.set_ylabel('é¢˜ç›®æ•°é‡')
        ax1.set_xticks(range(len(type_counts)))
        ax1.set_xticklabels(type_counts.index, rotation=45, ha='right')
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height)}', ha='center', va='bottom')
        
        # é¢˜å‹æ¯”ä¾‹é¥¼å›¾
        colors_pie = [self.colors['primary'], self.colors['secondary'], 
                     self.colors['accent'], self.colors['success'], 
                     self.colors['warning'], self.colors['info']]
        
        wedges, texts, autotexts = ax2.pie(type_counts.values, labels=type_counts.index, 
                                          autopct='%1.1f%%', startangle=90,
                                          colors=colors_pie[:len(type_counts)])
        ax2.set_title('é¢˜å‹æ¯”ä¾‹åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_path = self.output_dir / 'question_type_distribution.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"é¢˜å‹åˆ†å¸ƒå›¾å·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    def plot_chapter_importance_analysis(self, df: pd.DataFrame) -> str:
        """ç»˜åˆ¶ç« èŠ‚é‡è¦ç¨‹åº¦å’Œé¢˜å‹åˆ†å¸ƒåˆ†æå›¾ - ä¸ºäº†ç™¾ä¸‡å¹´è–ªï¼"""
        # åˆ†æreferå­—æ®µï¼Œæå–ç« èŠ‚ä¿¡æ¯
        chapter_data = []
        
        for _, row in df.iterrows():
            refer = str(row.get('refer', ''))
            question_type = str(row.get('type', ''))
            
            # ä»referä¸­æå–ç« èŠ‚å·
            chapter_match = re.search(r'ç¬¬(\d+)ç« ', refer)
            if chapter_match:
                chapter_num = int(chapter_match.group(1))
                chapter_data.append({
                    'chapter': chapter_num,
                    'type': question_type,
                    'refer': refer
                })
        
        if not chapter_data:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°ç« èŠ‚ç›¸å…³æ•°æ®")
            return ""
        
        # è½¬æ¢ä¸ºDataFrame
        chapter_df = pd.DataFrame(chapter_data)
        
        # ç»Ÿè®¡æ¯ä¸ªç« èŠ‚çš„é¢˜ç›®æ•°é‡
        chapter_counts = chapter_df['chapter'].value_counts().sort_index()
        
        # ç»Ÿè®¡æ¯ä¸ªç« èŠ‚çš„é¢˜å‹åˆ†å¸ƒ
        chapter_type_matrix = pd.crosstab(chapter_df['chapter'], chapter_df['type'])
        
        # åˆ›å»ºå­å›¾
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # å­å›¾1: ç« èŠ‚é‡è¦ç¨‹åº¦æ¡å½¢å›¾
        chapters = [f'ç¬¬{i}ç« ' for i in range(1, 8)]
        chapter_values = [chapter_counts.get(i, 0) for i in range(1, 8)]
        
        bars1 = ax1.bar(range(len(chapters)), chapter_values, 
                       color=[self.colors['primary'], self.colors['secondary'], 
                             self.colors['accent'], self.colors['success'],
                             self.colors['warning'], self.colors['info'], '#9C27B0'])
        ax1.set_title('ğŸ“Š ç« èŠ‚é‡è¦ç¨‹åº¦åˆ†æ (é¢˜ç›®æ•°é‡)', fontsize=16, fontweight='bold', pad=20)
        ax1.set_xlabel('è¯¾ç¨‹ç« èŠ‚', fontsize=12)
        ax1.set_ylabel('é¢˜ç›®æ•°é‡', fontsize=12)
        ax1.set_xticks(range(len(chapters)))
        ax1.set_xticklabels(chapters, rotation=45, ha='right')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{int(height)}', ha='center', va='bottom', fontweight='bold')
        
        # å­å›¾2: ç« èŠ‚é¢˜å‹åˆ†å¸ƒå †å æ¡å½¢å›¾
        chapter_type_matrix = chapter_type_matrix.reindex(range(1, 8), fill_value=0)
        chapter_type_matrix.plot(kind='bar', stacked=True, ax=ax2, 
                               color=[self.colors['primary'], self.colors['secondary'], 
                                     self.colors['accent'], self.colors['success'],
                                     self.colors['warning'], self.colors['info']])
        ax2.set_title('ğŸ¯ ç« èŠ‚é¢˜å‹åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold', pad=20)
        ax2.set_xlabel('è¯¾ç¨‹ç« èŠ‚', fontsize=12)
        ax2.set_ylabel('é¢˜ç›®æ•°é‡', fontsize=12)
        ax2.legend(title='é¢˜å‹', bbox_to_anchor=(1.05, 1), loc='upper left')
        ax2.set_xticklabels([f'ç¬¬{i}ç« ' for i in range(1, 8)], rotation=45, ha='right')
        
        # å­å›¾3: é¢˜å‹åœ¨å„ç« èŠ‚çš„åˆ†å¸ƒçƒ­åŠ›å›¾
        if not chapter_type_matrix.empty:
            sns.heatmap(chapter_type_matrix.T, annot=True, fmt='d', 
                       cmap='YlOrRd', ax=ax3, cbar_kws={'label': 'é¢˜ç›®æ•°é‡'})
            ax3.set_title('ğŸ”¥ é¢˜å‹-ç« èŠ‚çƒ­åŠ›å›¾åˆ†æ', fontsize=16, fontweight='bold', pad=20)
            ax3.set_xlabel('è¯¾ç¨‹ç« èŠ‚', fontsize=12)
            ax3.set_ylabel('é¢˜å‹', fontsize=12)
            ax3.set_xticklabels([f'ç¬¬{i}ç« ' for i in range(1, 8)], rotation=45, ha='right')
        
        # å­å›¾4: ç« èŠ‚è¦†ç›–ç‡é¥¼å›¾
        total_questions = len(df)
        chapter_coverage = [(count / total_questions) * 100 for count in chapter_values]
        
        wedges, texts, autotexts = ax4.pie(chapter_coverage, 
                                          labels=[f'ç¬¬{i}ç« \n({chapter_values[i-1]})' for i in range(1, 8)],
                                          autopct='%1.1f%%', startangle=90,
                                          colors=[self.colors['primary'], self.colors['secondary'], 
                                                 self.colors['accent'], self.colors['success'],
                                                 self.colors['warning'], self.colors['info'], '#9C27B0'])
        ax4.set_title('ğŸ“ˆ ç« èŠ‚è¦†ç›–ç‡åˆ†æ', fontsize=16, fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_path = self.output_dir / 'chapter_importance_analysis.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight', bbox_extra_artists=[])
        plt.close()
        
        self.logger.info(f"ç« èŠ‚é‡è¦ç¨‹åº¦åˆ†æå›¾å·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    def plot_knowledge_points_analysis(self, df: pd.DataFrame) -> str:
        """ç»˜åˆ¶çŸ¥è¯†ç‚¹åˆ†æå›¾"""
        # æå–çŸ¥è¯†ç‚¹æ•°æ®
        all_knowledge_points = []
        for kp_str in df['knowledge_points'].dropna():
            if kp_str != 'æœªè¯†åˆ«':
                points = [kp.strip() for kp in kp_str.split(';')]
                all_knowledge_points.extend(points)
        
        if not all_knowledge_points:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°çŸ¥è¯†ç‚¹æ•°æ®")
            return ""
        
        kp_counter = Counter(all_knowledge_points)
        top_10_kp = dict(kp_counter.most_common(10))
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # çŸ¥è¯†ç‚¹é¢‘ç‡æŸ±çŠ¶å›¾
        kp_names = list(top_10_kp.keys())
        kp_counts = list(top_10_kp.values())
        
        bars = ax1.barh(range(len(kp_names)), kp_counts, 
                       color=self.colors['secondary'])
        ax1.set_title('Top 10 æœ€å¸¸è€ƒçŸ¥è¯†ç‚¹', fontsize=14, fontweight='bold')
        ax1.set_xlabel('å‡ºç°é¢‘æ¬¡')
        ax1.set_yticks(range(len(kp_names)))
        ax1.set_yticklabels(kp_names)
        ax1.invert_yaxis()
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax1.text(width + 0.1, bar.get_y() + bar.get_height()/2.,
                    f'{int(width)}', ha='left', va='center')
        
        # çŸ¥è¯†ç‚¹è¦†ç›–ç‡åˆ†æ
        coverage_data = []
        for _, row in df.iterrows():
            kp_str = row['knowledge_points']
            if kp_str == 'æœªè¯†åˆ«' or pd.isna(kp_str):
                coverage_data.append('æœªè¯†åˆ«')
            else:
                kp_count = len([kp.strip() for kp in kp_str.split(';')])
                if kp_count == 1:
                    coverage_data.append('å•ä¸ªçŸ¥è¯†ç‚¹')
                elif kp_count <= 3:
                    coverage_data.append('2-3ä¸ªçŸ¥è¯†ç‚¹')
                else:
                    coverage_data.append('3+ä¸ªçŸ¥è¯†ç‚¹')
        
        coverage_counts = pd.Series(coverage_data).value_counts()
        
        wedges, texts, autotexts = ax2.pie(coverage_counts.values, 
                                          labels=coverage_counts.index,
                                          autopct='%1.1f%%', startangle=90,
                                          colors=[self.colors['primary'], 
                                                 self.colors['accent'],
                                                 self.colors['success'],
                                                 self.colors['warning']])
        ax2.set_title('é¢˜ç›®çŸ¥è¯†ç‚¹è¦†ç›–æƒ…å†µ', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_path = self.output_dir / 'knowledge_points_analysis.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"çŸ¥è¯†ç‚¹åˆ†æå›¾å·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    def create_interactive_dashboard(self, df: pd.DataFrame) -> str:
        """åˆ›å»ºäº¤äº’å¼ä»ªè¡¨æ¿"""
        # åˆ›å»ºå­å›¾
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('é¢˜å‹åˆ†å¸ƒ', 'æ¥æºåˆ†å¸ƒ', 'ç­”æ¡ˆå®Œæ•´æ€§', 'é¢˜ç›®å¤æ‚åº¦'),
            specs=[[{"type": "bar"}, {"type": "pie"}],
                   [{"type": "bar"}, {"type": "scatter"}]]
        )
        
        # é¢˜å‹åˆ†å¸ƒæŸ±çŠ¶å›¾
        type_counts = df['type'].value_counts()
        fig.add_trace(
            go.Bar(x=type_counts.index, y=type_counts.values,
                   name="é¢˜å‹åˆ†å¸ƒ", marker_color=self.colors['primary']),
            row=1, col=1
        )
        
        # æ¥æºåˆ†å¸ƒé¥¼å›¾
        source_counts = df['source'].value_counts()
        fig.add_trace(
            go.Pie(labels=source_counts.index, values=source_counts.values,
                   name="æ¥æºåˆ†å¸ƒ"),
            row=1, col=2
        )
        
        # ç­”æ¡ˆå®Œæ•´æ€§
        answer_status = df['has_answer'].value_counts()
        fig.add_trace(
            go.Bar(x=answer_status.index, y=answer_status.values,
                   name="ç­”æ¡ˆå®Œæ•´æ€§", marker_color=self.colors['secondary']),
            row=2, col=1
        )
        
        # é¢˜ç›®å¤æ‚åº¦æ•£ç‚¹å›¾
        fig.add_trace(
            go.Scatter(x=df['title_length'], y=df['answer_length'],
                      mode='markers', name="å¤æ‚åº¦åˆ†æ",
                      text=df['type'], hovertemplate='<b>%{text}</b><br>é¢˜ç›®é•¿åº¦: %{x}<br>ç­”æ¡ˆé•¿åº¦: %{y}',
                      marker=dict(color=df['title_length'], 
                                colorscale='Viridis', size=8)),
            row=2, col=2
        )
        
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title_text="åˆ†å¸ƒå¼ç³»ç»Ÿè€ƒè¯•é¢˜ç›®åˆ†æä»ªè¡¨æ¿",
            showlegend=False,
            height=800
        )
        
        # ä¿å­˜äº¤äº’å¼å›¾è¡¨
        output_path = self.output_dir / 'interactive_dashboard.html'
        fig.write_html(output_path)
        
        self.logger.info(f"äº¤äº’å¼ä»ªè¡¨æ¿å·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    def generate_exam_insights(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ç”Ÿæˆè€ƒè¯•æ´å¯ŸæŠ¥å‘Š"""
        insights = {
            'overview': {
                'total_questions': len(df),
                'total_sources': df['source'].nunique(),
                'question_types': df['type'].nunique(),
                'answer_coverage': (df['has_answer'] == 'æ˜¯').mean() * 100
            },
            'type_analysis': self.analyze_question_types(df),
            'knowledge_analysis': self.analyze_knowledge_points(df),
            'difficulty_analysis': {
                'avg_title_length': df['title_length'].mean(),
                'avg_answer_length': df[df['answer_length'] > 0]['answer_length'].mean(),
                'complex_questions': len(df[df['title_length'] > df['title_length'].quantile(0.75)])
            },
            'recommendations': self._generate_recommendations(df)
        }
        
        return insights
    
    def _generate_recommendations(self, df: pd.DataFrame) -> List[str]:
        """ç”Ÿæˆå­¦ä¹ å»ºè®®"""
        recommendations = []
        
        # åŸºäºé¢˜å‹åˆ†å¸ƒçš„å»ºè®®
        type_counts = df['type'].value_counts()
        most_common_type = type_counts.index[0]
        recommendations.append(f"é‡ç‚¹å…³æ³¨{most_common_type}ï¼Œå æ¯”{type_counts.iloc[0]/len(df)*100:.1f}%")
        
        # åŸºäºçŸ¥è¯†ç‚¹çš„å»ºè®®
        all_kp = []
        for kp_str in df['knowledge_points'].dropna():
            if kp_str != 'æœªè¯†åˆ«':
                all_kp.extend([kp.strip() for kp in kp_str.split(';')])
        
        if all_kp:
            kp_counter = Counter(all_kp)
            top_kp = kp_counter.most_common(3)
            recommendations.append(f"é«˜é¢‘çŸ¥è¯†ç‚¹ï¼š{', '.join([kp[0] for kp in top_kp])}")
        
        # åŸºäºç­”æ¡ˆå®Œæ•´æ€§çš„å»ºè®®
        answer_rate = (df['has_answer'] == 'æ˜¯').mean()
        if answer_rate < 0.5:
            recommendations.append("å»ºè®®è¡¥å……æ›´å¤šæ ‡å‡†ç­”æ¡ˆï¼Œæé«˜å¤ä¹ æ•ˆæœ")
        
        return recommendations
    
    def save_insights_report(self, insights: Dict[str, Any], output_path: str = None) -> str:
        """ä¿å­˜æ´å¯ŸæŠ¥å‘Š"""
        if output_path is None:
            output_path = self.output_dir / 'exam_insights_report.json'
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(insights, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"æ´å¯ŸæŠ¥å‘Šå·²ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            self.logger.error(f"æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
            return ""
    
    def generate_all_visualizations(self, csv_path: str = "output/questions_full.csv") -> Dict[str, str]:
        """ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
        # åŠ è½½æ•°æ®
        df = self.load_data(csv_path)
        if df.empty:
            self.logger.error("æ— æ³•åŠ è½½æ•°æ®ï¼Œåœæ­¢å¯è§†åŒ–ç”Ÿæˆ")
            return {}
        
        # ç”Ÿæˆå„ç§å›¾è¡¨
        results = {}
        
        try:
            # é¢˜å‹åˆ†å¸ƒå›¾
            results['type_distribution'] = self.plot_question_type_distribution(df)
            
            # ç« èŠ‚é‡è¦ç¨‹åº¦åˆ†æå›¾
            results['chapter_importance'] = self.plot_chapter_importance_analysis(df)
            
            # çŸ¥è¯†ç‚¹åˆ†æå›¾
            results['knowledge_analysis'] = self.plot_knowledge_points_analysis(df)
            
            # äº¤äº’å¼ä»ªè¡¨æ¿
            results['interactive_dashboard'] = self.create_interactive_dashboard(df)
            
            # ç”Ÿæˆæ´å¯ŸæŠ¥å‘Š
            insights = self.generate_exam_insights(df)
            results['insights_report'] = self.save_insights_report(insights)
            
            self.logger.info("æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"å¯è§†åŒ–ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        
        return results

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¯è§†åŒ–åŠŸèƒ½"""
    visualizer = ExamVisualizer()
    
    # ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–
    results = visualizer.generate_all_visualizations()
    
    print("\n=== å¯è§†åŒ–åˆ†æå®Œæˆ ===")
    for name, path in results.items():
        if path:
            print(f"{name}: {path}")

if __name__ == "__main__":
    main()